{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning tweets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMovLW/xYydcv3ptuI8mdmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed-Shatla/NLP-data-cleaning/blob/main/Cleaning_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wGMGAOCcbHng"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#downloading"
      ],
      "metadata": {
        "id": "6hl4zRz3cP6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('twitter_samples')"
      ],
      "metadata": {
        "id": "IERzFriVbbUi",
        "outputId": "9ba5cac7-634e-4386-e5d7-0cf1a8110fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading data"
      ],
      "metadata": {
        "id": "dnLKwE-XcgFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import twitter_samples\n",
        "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "ldPQy3sfbziE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data cleaning"
      ],
      "metadata": {
        "id": "yk_7zaS9cjb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "GX8y_9WjcjCW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanText(text):\n",
        "  text= re.sub(r'#[\\S|_]*','',text) #hashtage removing\n",
        "  text= re.sub(r'@[\\S|_]*','',text) #username removing\n",
        "  text= re.sub(r'https?:\\/\\/\\S+','',text) #hyperlink removing\n",
        "  text = re.sub(r'\\W',' ',text) #remove any emotions\n",
        "  text = re.sub(r'\\d+','',text) #remove any standalone digits\n",
        "  text = re.sub(r'^\\s+','',text)#remove spaces that at start of the sentences\n",
        "  text = re.sub(r'\\s+$','',text)#remove spaces that at end of the sentences\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "0rkSHwkhcLCX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleanText(pos_tweets[0])"
      ],
      "metadata": {
        "id": "Q8-VXq75fe04",
        "outputId": "6d618270-f528-4996-9bae-8029d9185a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for being top engaged members in my community this week'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "xHTassmjjY1h",
        "outputId": "73fcb4df-ea98-4561-be9c-560f7b9d0767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "def process_on_tweets(tweets):\n",
        "  result=[]\n",
        "  for tweet in tweets:\n",
        "    tweet = cleanText(tweet)\n",
        "    tweet = tweet.split()\n",
        "    tweet=[word for word in tweet if word.lower() not in stop_words]\n",
        "\n",
        "    ps = PorterStemmer()\n",
        "    tweet=[ps.stem(word) for word in tweet]\n",
        "\n",
        "    result.append(tweet)\n",
        "  return result"
      ],
      "metadata": {
        "id": "E-fXmeTsflF1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tweets = process_on_tweets(pos_tweets)\n"
      ],
      "metadata": {
        "id": "dB2gwMBPj0AZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,5):\n",
        "  print(pos_tweets[i])"
      ],
      "metadata": {
        "id": "7etOlpPliiXB",
        "outputId": "470f7fd8-0f23-4279-906a-716fa0136d95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['top', 'engag', 'member', 'commun', 'week']\n",
            "['hey', 'jame', 'odd', 'pleas', 'call', 'contact', 'centr', 'abl', 'assist', 'mani', 'thank']\n",
            "['listen', 'last', 'night', 'bleed', 'amaz', 'track', 'scotland']\n",
            "['congrat']\n",
            "['yeaaaah', 'yippppi', 'accnt', 'verifi', 'rqst', 'succeed', 'got', 'blue', 'tick', 'mark', 'fb', 'profil', 'day']\n"
          ]
        }
      ]
    }
  ]
}